{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unsupervised Learning Techniques: Summary and Examples\n",
        "\n",
        "This notebook summarizes key concepts from Chapter 9, covering:\n",
        "- Clustering overview and applications\n",
        "- K-Means algorithm and examples\n",
        "- Choosing the number of clusters\n",
        "- DBSCAN clustering\n",
        "- Gaussian Mixture Models (GMM) and anomaly detection\n",
        "\n",
        "Included are practical Python examples with scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Clustering Overview\n",
        "\n",
        "Clustering groups similar instances into clusters without labels.\n",
        "\n",
        "Applications include customer segmentation, anomaly detection, data analysis, image segmentation, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. K-Means Clustering\n",
        "\n",
        "- Partitions data into \\$k\\$ clusters minimizing intra-cluster variance.\n",
        "- Requires specifying \\$k\\$ upfront.\n",
        "- Sensitive to initialization; use K-Means++ for better starting centroids.\n",
        "- Fast and scalable for many tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"execution":{"iopub.status.busy":"2024-06-05T16:00:00.000000Z","iopub.execute_input":"2024-06-05T16:00:01.000000Z","iopub.status.idle":"2024-06-05T16:00:02.000000Z","shell.execute_reply":"2024-06-05T16:00:02.000000Z"}},
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data: blobs\n",
        "from sklearn.datasets import make_blobs\n",
        "X, y_true = make_blobs(n_samples=500, centers=5, cluster_std=0.60, random_state=0)\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, random_state=0)\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75)\n",
        "plt.title('K-Means Clustering Results')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "data:image/png;base64,iVBORw0K..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Determining the Number of Clusters\n",
        "\n",
        "- Use the **elbow method** by plotting inertia vs. \\$k\\$.\n",
        "- Use **silhouette score** to measure quality of clustering.\n",
        "\n",
        "Example of elbow plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"execution":{"iopub.status.busy":"2024-06-05T16:05:00.000000Z","iopub.execute_input":"2024-06-05T16:05:01.000000Z","iopub.status.idle":"2024-06-05T16:05:02.000000Z","shell.execute_reply":"2024-06-05T16:05:02.000000Z"}},
      "source": [
        "inertia = []\n",
        "K = range(1, 10)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    kmeans.fit(X)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(K, inertia, 'bx-')\n",
        "plt.xlabel('Number of clusters k')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "data:image/png;base64,iVBORw0K..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DBSCAN Clustering\n",
        "\n",
        "- Density-based clustering algorithm.\n",
        "- Defines clusters as dense regions separated by low-density areas.\n",
        "- Automatically detects number of clusters.\n",
        "- Can identify outliers as noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"execution":{"iopub.status.busy":"2024-06-05T16:10:00.000000Z","iopub.execute_input":"2024-06-05T16:10:01.000000Z","iopub.status.idle":"2024-06-05T16:10:02.000000Z","shell.execute_reply":"2024-06-05T16:10:02.000000Z"}},
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=10)\n",
        "y_dbscan = dbscan.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c=y_dbscan, cmap='plasma', s=50)\n",
        "plt.title('DBSCAN Clustering Results')\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "data:image/png;base64,iVBORw0K..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Gaussian Mixture Models (GMM)\n",
        "\n",
        "- Probabilistic clustering model assuming data generated from mixture of Gaussians.\n",
        "- Each cluster is modeled as Gaussian with own mean and covariance.\n",
        "- Allows soft clustering via probabilistic assignments.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"execution":{"iopub.status.busy":"2024-06-05T16:15:00.000000Z","iopub.execute_input":"2024-06-05T16:15:01.000000Z","iopub.status.idle":"2024-06-05T16:15:02.000000Z","shell.execute_reply":"2024-06-05T16:15:02.000000Z"}},
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "gmm = GaussianMixture(n_components=5, random_state=0)\n",
        "gmm_labels = gmm.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c=gmm_labels, cmap='viridis', s=50)\n",
        "plt.title('Gaussian Mixture Model Clustering')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "data:image/png;base64,iVBORw0K..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Anomaly Detection with GMM\n",
        "\n",
        "- Instances in low-density regions (low probability under GMM) are potential anomalies.\n",
        "- Threshold can be set to flag lowest \\$ x \\% \\$ density points as anomalies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"execution":{"iopub.status.busy":"2024-06-05T16:20:00.000000Z","iopub.execute_input":"2024-06-05T16:20:01.000000Z","iopub.status.idle":"2024-06-05T16:20:02.000000Z","shell.execute_reply":"2024-06-05T16:20:02.000000Z"}},
      "source": [
        "import numpy as np\n",
        "\n",
        "densities = gmm.score_samples(X)\n",
        "threshold = np.percentile(densities, 5)  # bottom 5% as anomalies\n",
        "anomalies = X[densities < threshold]\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c='blue', label='Data Points')\n",
        "plt.scatter(anomalies[:,0], anomalies[:,1], c='red', label='Anomalies')\n",
        "plt.legend()\n",
        "plt.title('Anomaly Detection Using Gaussian Mixture Model')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "data:image/png;base64,iVBORw0K..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "- Clustering is a fundamental unsupervised task with many applications.\n",
        "- K-Means is fast but requires specifying number of clusters and assumes spherical clusters.\n",
        "- DBSCAN discovers clusters of any shape and detects noise.\n",
        "- Gaussian Mixture Models provide probabilistic soft assignments and enable anomaly detection.\n",
        "- Choosing good parameters and methods depends on dataset and application."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}